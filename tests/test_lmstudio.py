import os
import time
from openai import OpenAI
from dotenv import load_dotenv

def test_lm_studio_connection():
    """
    Tests the connection to the LM Studio local LLM service and gets a response.
    """
    try:
        # --- 1. è¨­å®šèˆ‡ç’°å¢ƒè®Šæ•¸è¼‰å…¥ ---
        load_dotenv()
        base_url = os.getenv("LM_STUDIO_BASE_URL")
        
        if not base_url:
            print("âŒ éŒ¯èª¤: .env æª”æ¡ˆä¸­æ‰¾ä¸åˆ° LM_STUDIO_BASE_URLã€‚")
            print("è«‹ç¢ºèª .env æª”æ¡ˆå­˜åœ¨,ä¸”åŒ…å« 'LM_STUDIO_BASE_URL=http://127.0.0.1:1234/v1'")
            return

        # --- 2. åˆå§‹åŒ– OpenAI ç”¨æˆ¶ç«¯ ---
        # LM Studio ä¸éœ€è¦ API é‡‘é‘°,ä½† openai SDK éœ€è¦ä¸€å€‹å€¼,å¯ä»¥æ˜¯ä»»ä½•å­—ä¸²ã€‚
        client = OpenAI(base_url=base_url, api_key="lm-studio")
        
        # --- 3. ç™¼é€æ¸¬è©¦è¨Šæ¯ ---
        test_message = "ä½ å¥½,æˆ‘æƒ³é»ä¸€ä»½é£¯ç³°"
        history = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€å€‹é»é¤ç³»çµ±,è«‹ä½¿ç”¨ç¹é«”ä¸­æ–‡å›ç­”ã€‚"},
            {"role": "user", "content": test_message},
        ]
        
        print("ğŸš€ æ­£åœ¨é€£æ¥åˆ° LM Studio...")
        print(f"Given: LM Studio åœ¨ {base_url} é‹è¡Œ")
        print(f"When:  ç™¼é€æ¸¬è©¦è¨Šæ¯ã€Œ{test_message}ã€")
        print("-" * 40)

        start_time = time.time()

        completion = client.chat.completions.create(
            model="local-model", # å°æ–¼æœ¬åœ°æ¨¡å‹,æ­¤åç¨±å¯ç‚ºä»»æ„å€¼
            messages=history,
            temperature=0.7,
        )

        end_time = time.time()
        
        # --- 4. è™•ç†ä¸¦é¡¯ç¤ºå›æ‡‰ ---
        response_message = completion.choices[0].message.content
        response_time = end_time - start_time
        
        history.append({"role": "assistant", "content": response_message})

        print("Then:  æ‡‰æ”¶åˆ°ç¹é«”ä¸­æ–‡å›æ‡‰")
        print("-" * 40)
        print("ğŸ–¥ï¸  çµ‚ç«¯é¡¯ç¤ºå®Œæ•´å°è©±:")
        for message in history:
            role_display = "ä½¿ç”¨è€…" if message['role'] == 'user' else 'å°å¹«æ‰‹' if message['role'] == 'assistant' else 'ç³»çµ±'
            print(f"  [{role_display}]: {message['content']}")
        print("-" * 40)
        
        print(f"â±ï¸  å›æ‡‰æ™‚é–“: {response_time:.2f} ç§’")
        
        if response_time <= 5:
            print("âœ… æˆåŠŸ: å›æ‡‰æ™‚é–“åœ¨ 5 ç§’å…§ã€‚ à¦¸à¦¨")
        else:
            print("âš ï¸  æ³¨æ„: å›æ‡‰æ™‚é–“è¶…é 5 ç§’ã€‚ à¦¸à¦¨")

    except Exception as e:
        print(f"\nâŒ å¤±æ•—: é€£æ¥æˆ–è«‹æ±‚æ™‚ç™¼ç”ŸéŒ¯èª¤ã€‚ à¦¸à¦¨")
        print(f"   è«‹ç¢ºèª LM Studio æ­£åœ¨ http://127.0.0.1:1234 é‹è¡Œ,ä¸¦ä¸” Qwen2.5:7B æ¨¡å‹å·²å®Œå…¨è¼‰å…¥ã€‚ à¦¸à¦¨")
        print(f"   éŒ¯èª¤è©³ç´°è³‡è¨Š: {e}")

if __name__ == "__main__":
    test_lm_studio_connection()
